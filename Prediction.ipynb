{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this seminar assignment, we will explore the data and build machine-learning models that predict the biodegradability of chemicals.\n",
    "\n",
    "[Data set](https://www.openml.org/search?type=data&status=active&id=1494&sort=runs) containing values for \n",
    "**41 attributes** (`molecular descriptors`) used to classify 1055 chemicals into **2 classes** (`ready` and `not ready` biodegradable).\n",
    "\n",
    "## Attribute information\n",
    "\n",
    "41 molecular descriptors (features) and 1 experimental class:\n",
    "\n",
    "| Feature Name | Feature Information (Molecular Descriptor) | Type | Distinct values / Missing attributes |\n",
    "| --- | --- | --- | --- |\n",
    "| Class (target) | ready biodegradable (RB) and not ready biodegradable (NRB) | nominal | 2/0 |\n",
    "| V1  | SpMax_L: Leading eigenvalue from Laplace matrix | numeric | 440/0 |\n",
    "| V2  | J_Dz(e): Balaban-like index from Barysz matrix weighted by Sanderson electronegativity | numeric | 1022/0 |\n",
    "| V3  | nHM: Number of heavy atoms | numeric | 11/0 |\n",
    "| V4  | F01\\[N-N\\]: Frequency of N-N at topological distance 1 | numeric | 4/0 |\n",
    "| V5  | F04\\[C-N\\]: Frequency of C-N at topological distance 4 | numeric | 16/0 |\n",
    "| V6  | NssssC: Number of atoms of type ssssC | numeric | 13/0 |\n",
    "| V7  | nCb-: Number of substituted benzene C(sp2) | numeric | 15/0 |\n",
    "| V8  | C%: Percentage of C atoms | numeric | 188/0 |\n",
    "| V9  | nCp: Number of terminal primary C(sp3) | numeric | 15/0 |\n",
    "| V10 | nO: Number of oxygen atoms | numeric | 12/0 |\n",
    "| V11 | F03\\[C-N\\]: Frequency of C-N at topological distance 3 | numeric | 21/0 |\n",
    "| V12 | SdssC: Sum of dssC E-states | numeric | 384/0 |\n",
    "| V13 | HyWi_B(m): Hyper-Wiener-like index (log function) from Burden matrix weighted by mass | numeric | 756/0 |\n",
    "| V14 | LOC: Lopping centric index | numeric | 373/0 |\n",
    "| V15 | SM6_L: Spectral moment of order 6 from Laplace matrix | numeric | 510/0 |\n",
    "| V16 | F03\\[C-O\\]: Frequency of C - O at topological distance 3 | numeric | 24/0 |\n",
    "| V17 | Me: Mean atomic Sanderson electronegativity (scaled on Carbon atom) | numeric | 167/0 |\n",
    "| V18 | Mi: Mean first ionization potential (scaled on Carbon atom) | numeric | 125/0 |\n",
    "| V19 | nN-N: Number of N hydrazines | numeric | 3/0 |\n",
    "| V20 | nArNO2: Number of nitro groups (aromatic) | numeric | 4/0 |\n",
    "| V21 | nCRX3: Number of CRX3 | numeric | 4/0 |\n",
    "| V22 | SpPosA_B(p): Normalized spectral positive sum from Burden matrix weighted by polarizability | numeric | 352/0 |\n",
    "| V23 | nCIR: Number of circuits | numeric | 13/0 |\n",
    "| V24 | B01\\[C-Br\\]: Presence/absence of C - Br at topological distance 1 | numeric | 2/0 |\n",
    "| V25 | B03\\[C-Cl\\]: Presence/absence of C - Cl at topological distance 3 | numeric | 2/0 |\n",
    "| V26 | N-073: Ar2NH / Ar3N / Ar2N- |  numeric   | 4/0    |\n",
    "| V27 | SpMax_A: Leading eigenvalue from adjacency matrix (Lovasz-Pelikan index) | numeric | 329/0 |\n",
    "| V28 | Psi\\_i\\_1d: Intrinsic state pseudoconnectivity index - type 1d | numeric | 205/0 |\n",
    "| V29 | B04\\[C-Br\\]: Presence/absence of C - Br at topological distance 4 | numeric | 2/0 |\n",
    "| V30 | SdO: Sum of dO E-states | numeric | 470/0 |\n",
    "| V31 | TI2_L: Second Mohar index from Laplace matrix | numeric | 553/0 |\n",
    "| V32 | nCrt: Number of ring tertiary C(sp3) | numeric | 8/0 |\n",
    "| V33 | C-026: R--CX--R | numeric | 11/0 |\n",
    "| V34 | F02\\[C-N\\]: Frequency of C - N at topological distance 2 | numeric | 16/0 |\n",
    "| V35 | nHDon: Number of donor atoms for H-bonds (N and O) | numeric | 8/0 |\n",
    "| V36 | SpMax_B(m): Leading eigenvalue from Burden matrix weighted by mass | numeric | 705/0 |\n",
    "| V37 | Psi\\_i\\_A: Intrinsic state pseudoconnectivity index - type S average |  numeric   | 624/0    |\n",
    "| V38 | nN: Number of Nitrogen atoms | numeric | 8/0 |\n",
    "| V39 | SM6_B(m): Spectral moment of order 6 from Burden matrix weighted by mass | numeric | 862/0 |\n",
    "| V40 | nArCOOR: Number of esters (aromatic) | numeric | 5/0 |\n",
    "| V41 | nX: Number of halogen atoms | numeric | 17/0 |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the dataset. How balanced is the target variable (degradability)?\n",
    "dataset_train = pd.read_csv(\"train.csv\")\n",
    "dataset_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "X_train = dataset_train.iloc[:, :-1].values\n",
    "y_train = dataset_train.iloc[:, -1].values\n",
    "\n",
    "X_test = dataset_test.iloc[:, :-1].values\n",
    "y_test = dataset_test.iloc[:, -1].values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in X: 82\n",
      "Number of missing values in y: 0\n",
      "Sample 689 has more than one missing value\n",
      "Total number of samples with missing values: 81\n",
      "Number of samples in class 1: 564\n",
      "Number of samples in class 2: 282\n",
      "Indices of samples with missing values: [10, 13, 32, 42, 55, 60, 64, 66, 68, 69, 73, 78, 87, 89, 98, 104, 130, 131, 146, 152, 158, 171, 179, 188, 189, 223, 242, 246, 260, 268, 292, 302, 313, 326, 338, 360, 361, 373, 375, 390, 403, 410, 411, 431, 432, 439, 470, 498, 509, 511, 528, 544, 546, 556, 573, 577, 585, 589, 593, 595, 602, 612, 617, 648, 649, 665, 676, 678, 680, 689, 706, 719, 748, 752, 764, 766, 767, 791, 806, 809, 839]\n"
     ]
    }
   ],
   "source": [
    "num_missing = np.sum(np.isnan(X_train))\n",
    "print(f\"Number of missing values in X: {num_missing}\")\n",
    "num_missing = np.sum(np.isnan(y_train))\n",
    "print(f\"Number of missing values in y: {num_missing}\")\n",
    "\n",
    "# Check if there are any missing values present in the dataset\n",
    "# If there are, print the index of the sample\n",
    "total_missing = 0\n",
    "missing_indices = []\n",
    "for i in range(len(X_train)):\n",
    "    if np.isnan(X_train[i]).any():\n",
    "        missing_indices.append(i)\n",
    "        # Also check if line contains more than one missing value\n",
    "        if len(np.where(np.isnan(X_train[i]))[0]) > 1:\n",
    "            print(\"Sample {} has more than one missing value\".format(i))\n",
    "        total_missing += 1\n",
    "print(\"Total number of samples with missing values: {}\".format(total_missing))\n",
    "\n",
    "# Check how balanced is the target variable\n",
    "print(\"Number of samples in class 1: {}\".format(np.sum(y_train == 1)))\n",
    "print(\"Number of samples in class 2: {}\".format(np.sum(y_train == 2)))\n",
    "print(\"Indices of samples with missing values: {}\".format(sorted(missing_indices)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Taking care of the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values with the mean of the column\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "imputer.fit(X_train)\n",
    "X_train = imputer.transform(X_train)\n",
    "X_test = imputer.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Encoding dependent variable ([1,2] -> [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "y_train = labelencoder.fit_transform(y_train)\n",
    "y_test = labelencoder.transform(y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Feature Scaling\n",
    "\n",
    "Use `standardization`: $X = \\frac{X - \\mu}{\\sigma}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Visualizing the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(X, y, model, folds=5):\n",
    "    scores_list = []\n",
    "    X = X.copy()\n",
    "    y = y.copy()\n",
    "    \n",
    "    kf = KFold(n_splits=folds, shuffle=True)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        # Split the data\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        y_pred = model.predict(X_test)\n",
    "        scores = {\n",
    "            'Accuracy': model.score(X_test, y_test),\n",
    "            'F1': f1_score(y_test, y_pred),\n",
    "            'Precision': precision_score(y_test, y_pred),\n",
    "            'Recall': recall_score(y_test, y_pred),\n",
    "            'AUC': roc_auc_score(y_test, y_pred)\n",
    "        }\n",
    "        \n",
    "        \n",
    "        scores_list.append(scores)\n",
    "    return scores_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    model_score = model.score(X_test, y_test)\n",
    "    # Predict the labels\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    scores = cross_validate(X_train, y_train, model)\n",
    "    \n",
    "    print(\"Training accuracy: {}, Test accuracy: {} \".format(model.score(X_train, y_train), model_score))\n",
    "    \n",
    "    # print(f\"score: {scores}\")\n",
    "    return scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9680851063829787, Test accuracy: 0.8133971291866029 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Accuracy': 0.8058823529411765,\n",
       "  'F1': 0.6526315789473683,\n",
       "  'Precision': 0.6458333333333334,\n",
       "  'Recall': 0.6595744680851063,\n",
       "  'AUC': 0.7606815429856426},\n",
       " {'Accuracy': 0.7810650887573964,\n",
       "  'F1': 0.6890756302521008,\n",
       "  'Precision': 0.6949152542372882,\n",
       "  'Recall': 0.6833333333333333,\n",
       "  'AUC': 0.7590978593272171},\n",
       " {'Accuracy': 0.8165680473372781,\n",
       "  'F1': 0.6930693069306931,\n",
       "  'Precision': 0.6481481481481481,\n",
       "  'Recall': 0.7446808510638298,\n",
       "  'AUC': 0.7944715730728985},\n",
       " {'Accuracy': 0.7514792899408284,\n",
       "  'F1': 0.661290322580645,\n",
       "  'Precision': 0.7454545454545455,\n",
       "  'Recall': 0.5942028985507246,\n",
       "  'AUC': 0.7271014492753624},\n",
       " {'Accuracy': 0.8402366863905325,\n",
       "  'F1': 0.7768595041322315,\n",
       "  'Precision': 0.7580645161290323,\n",
       "  'Recall': 0.7966101694915254,\n",
       "  'AUC': 0.8301232665639445}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(DecisionTreeClassifier(random_state=0), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "219284b42a864982ed2952f129d7a94d2845dabbbd34dbf2f569db19af2d38f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
